

Marks (Class): // could probably just do integers and not even use a class, class would just provide more information if we need it.
row: int
column: int
player: int (?)
type: String (?)

Grid (Class):
tiles: Marks[][] (or 2D list)
numMarks: int
setMark(Mark, row, col): void
computeState(): int  // return the "static evaluation of the position"

BoardPosition (Class):
    depth: int (?)
    move (?) -> this is the move that is being represented in this position (board state). i.e. placing an X at (2, 1). 
                    this is how we know what move the computer will make after minimax() completes, as the node it chooses will have this move associated with it.
    children: Position[] (or list)

//===========================================================================
// How to get the static evaluation of the position?

// we can't just sum all of the values of the grid up, as the evaluation would
// always equal either -1 or +1, depending on whether the human player is an
// X or O since Tic-Tac-Toe alternates turns between both players.

The board state found at the leaves of the position tree will have either a winning configuration or a tie. A winning configuration
can be evaluated to a score of 10 or -10, depending on whether the minimizer or maximizer has won, or a 0 for a tie. 
Additionally, the depth of a winning state may also be able to influence the evaluation score, as a higher depth (lower depth value) in the tree
means that it took less turns to get there and is therefore probably more favorable. A tie, on the other hand, will always appear at the maximum
possible depth. 
One possible route to incorporating the depth of the tree into a evaluation score is to multiply the score by depth; however, since the higher depths are
more valuable and the minimizer are looking for minimum/maximum values, instead we could multiply the evaluation score by ((MAX_DEPTH + 1) - depth). 
For 9 possible turns in a Tic-Tac-Toe game, the max depth is 9. Example:
- A winning maximizer board on turn 4 would have an evaluated score of (10)*((9 + 1) - 4) = 60. if another child position node in the tree had a winning
    board state 2 more depths (turns) later in the tree which was then returned by its parents, that score would evaluate to (10)*((9 + 1) - 6) = 40.
    Choosing between the two, minimax() should select the position with the score of 60 for the maximizer, which makes sense since it wins sooner than the
    alternative.

minimax() has a concept of "position", which I guess is the current configuration of the game board. "position"s are structured in a tree graph,
and have n children, where n is the number of possible moves a player can choose from to take.
That being said, the more Marks there are on the board, the less children are available; this is proportional to the number
of empty tiles on the board. At depth 0 (the root position), there are 9 possible moves, at depth 1, there are 8 possible moves, etc. 

- Q: is 9 possible at depth 0 (9 empty tiles) or is minimax called when the human player makes a move; meaning there would be only 8 tiles to choose from (8 children) (?)




//*********************************************************************************************************************************************************
//*********************************************************************************************************************************************************
// invalid ideas
//*********************************************************************************************************************************************************
// this block was brainstorming that I don't think will work, and have a better 
// idea later, but I still decided to leave this in.
//*********************************************************************************
//  levels of board states (with rating/multiplier/score in parentheses):
//  three in a row (horizontally, vertically, diagonally): (3) -> winning move, highest score
//  two in a row (horizontally, vertically, diagonally): (2)
//  two with a space in between (horizontally, vertically, diagonally): (2)
//  a lone mark: (1)
//
// if iterating over each tile, might need a way of reducing redundancies
// i.e. X| |X
//      -----
//       | |
//      -----
//      X| | 
// if iterating over each tile, then the top row's favorable state of two with a
//  space between would be counted twice; same with the diagonal and vertical
//  sequences.
//  Does this even matter? Would redundancies create some kind of extra weighting?
//***************************************************************************
// This might be the better solution?
// Maybe each row, column and diagonal could be evaluated, since the winning conditions of Tic-Tac-Toe are
// only along the rows, columns and diagonals; to me it follows that any move along these lines should be evaluated.
// I think the ordering of favorable game states above might mean that you could simply
// sum the "values" of player marks when taking this approach; such as if X is the maximizer, we could assign every
// X the value of 1. Then that would make O the minimizer and we could assign every O
// the value of -1. a blank tile would just have a value of 0 (might not even be necessary).

// i.e. X|O|X
//      -----
//       |O|
//      -----
//      X| |
// In this example, X is the maximizer (therefore has a multiplier of +1), and O is the minimizer (and 
//  has a multiplier of -1).
// The first row is evaluated. Since there are two X's (for a total value of 2*+1 = 2), and one O (for a total value of 1*-1 = -1), and so this row gets a
//  value of 1. the second row is evaluated, and has a value of -1. the third row has a value of 1.
//  The first column is evaluated. It has two X's, for a value of +2. the second row has a value of -2, and the third row has a value of +1.
//  The top-left -> bottom-right diagonal is evaluated, and has a value of 0. the other diagonal is evaluated, and has a total value of +1.
//  So, in total, this board state evaluation would be 1-1+1+2-2+1+0+1 = 3.
//*********************************************************************************************************************************************************
//*********************************************************************************************************************************************************